\chapter{AutoAFIDs: Automatic Anatomical Fiducial Localization} \label{chap:AutoAFIDs}
\newpage
\sloppy
This chapter is largely based on:
\begin{itemize}[noitemsep,topsep=0pt]
	\item Taha, A., Bansal, D., Snyder, M., et al. AutoAFIDs: Automatic brain landmark detection for quality control, stereotactic targeting, and brain charting. In-Prep.
\end{itemize}

\section{Introduction}
\subsection{Brain Coordinates in Neuroimaging and Neurosurgery}
Three-dimensional Cartesian coordinates (x, y, z) offer a convenient and precise framework to represent brain structures. This abstraction underlies a broad range of applications in both neuroimaging and neurosurgical workflows, enabling reproducibility \cite{Dockes2020-nw}, cross-subject comparison \cite{Glasser2016-ko}, and multimodal data integration \cite{Uludag2014-qz}. In research, coordinates form the backbone of meta-analytic platforms such as \texttt{NeuroSynth} \cite{Yarkoni2011-sr} and \texttt{NeuroQuery} \cite{Dockes2020-nw}, which aggregate reported coordinates from thousands of studies to identify consistent associations between brain and behavior. In clinical contexts, neuromodulation targets and optimal stimulation zones are represented by coordinates relative to the major anatomical landmarks \cite{Horn2017-bi} such as anterior and posterior commissure (AC and PC), guiding trajectory planning and enabling retrospective outcome analysis. Across both domains, coordinates are a shared spatial language for modeling and navigating the brain.

\subsection{Automatic Landmark Localization}
The manual localization of brain landmarks is often time-intensive, cognitively demanding, and subject to inter-rater variability \cite{Abbass2022-lf, Lau2019-eh,Pallavaram2008-zr}. Even with detailed annotation protocols, raters require training to achieve consistency \cite{Lau2019-eh}. These challenges pose a barrier to scaling coordinate-based workflows across large datasets and neuroimaging pipelines. To address this bottleneck, deep learning (DL) methods offer a promising avenue for automatic landmark detection in brain MRI. These approaches typically fall into two paradigms: (1) coordinate regression \cite{Neupane2024-vt} and (2) heatmap-based localization \cite{Payer2016-ik}. In coordinate regression, a network directly outputs the x,y,z coordinates of each landmark (often via fully connected layers or global pooling). In heatmap-based methods, the network predicts a probability map (often a Gaussian “fuzzy” blob) for each landmark, and the peak of the heatmap is taken as the location. Heatmap regression has become especially popular because it retains spatial context and allows the network to localize landmarks in a fully convolutional manner.

\subsection{Deep Learning Approaches}
DL has revolutionized computer vision over the past decade, with regression-based convolutional networks now widely used for tasks like facial landmark detection, pose estimation, and image registration \cite{Lathuiliere2018-oy}. While medical imaging adopted these tools more gradually, fully convolutional networks—particularly U-Net and its 3D variants—have since become foundational for segmentation and anatomical localization tasks \cite{Akkus2017-eh, Falk2019-us}. Variants such as V-Net and cascaded U-Nets improve spatial precision by capturing both global context and local detail, while architectures like the spatial configuration network (SCN) \cite{Payer2016-ik, Payer2019-sn} and multi-task cascaded CNNs \cite{Zhang2017-dc} embed geometric priors to enhance performance in data-scarce settings. More recently, self-configuring pipelines like nnLandmark \cite{Ertl2025-wu} and attention-based models such as H3DE-Net \cite{Huang2025-vt} have streamlined deployment and improved model efficiency. Despite these advances, relatively limited studies have adapted such innovations to the detection of brain landmarks central to stereotactic targeting and coordinate-based neuroimaging \cite{Edwards2021-su}. Given their consistent anatomy and clinical importance, AC-PC detection represents a promising use case for applying modern deep learning techniques to improve automation, reproducibility, and standardization in brain mapping workflows.

\subsection{Limitations in the field}
Several barriers limit the broader utility of these DL techniques. First, well-annotated, publicly available datasets with standardized brain landmarks remain scarce, which constrains training, benchmarking, and validation. Second, many existing models are not open-source, are difficult to reproduce, or lack adherence to FAIR (Findable, Accessible, Interoperable, and Reusable) data principles. Third, to the best of our knowledge, no automated workflows are built in environments compatible with the Brain Imaging Data Structure (BIDS; (Gorgolewski et al., 2016)), which impedes integration with modern neuroimaging pipelines and limits accessibility for the broader scientific community. As a result, the full potential of automated coordinate-based analysis for applications such as registration quality control, brain morphometry, or lifespan brain charting remains underrealized.

\subsection{Our Proposed Approach}
In this work, we present \texttt{AutoAFIDs}, a BIDS-App for automatic landmark detection using deep learning. We trained and tested \texttt{AutoAFIDs} using a curated open-access dataset of MRI scans (n = 202) across a range of MRI field strengths (1.5, 3, and 7T) and conditions (healthy, abnormal ventricles, and neurodegenerative) with 20,000+ landmarks manually localized by human raters. \texttt{AutoAFIDs} demonstrated a landmark localization accuracy comparable to human raters. We showcase the broad utility of \texttt{AutoAFIDs} for two downstream applications which we make available to end-users: 1) quality control of image registration, 2) stereotactic target localization. By applying \texttt{AutoAFIDs} on over 2,000 MRI scans from individuals aged 18 to 100, we uncovered millimetric differences in brain structure that distinguish healthy brain changes from early signs of neurodegenerative disease.

\section{Methods}
\subsection{Problem Definition}
\label{sec:problemstatement}
The objective of this study is to localize anatomical fiducial points distributed across multiple brain regions using a supervised deep learning framework. Let $\mathcal{V} \subset \mathbb{R}^3$ denote a 3D brain volume, and let $\{p_1, p_2, \ldots, p_L\}$ represent the set of $L$ target landmark coordinates, where each $p_\ell \in \mathbb{R}^3$ denotes the location of the $\ell^{\text{th}}$ anatomical point of interest.

We formulate this as a regression problem in which the model learns to predict a smooth, continuous-valued distance map centered on the target landmark. For each voxel $v \in \mathcal{V}$ and landmark $\ell$, the ground truth target $D^\ell(v)$ is defined as:

\begin{equation}
D^\ell(v) = \lVert v - p_\ell \rVert_2
\end{equation}

To enhance stability and spatial resolution, we apply an exponential decay to the predicted distance map:

\begin{equation}
T^\ell(v) = \exp(-\alpha \cdot D^\ell(v))
\end{equation}

where $\alpha$ is a fixed scaling factor controlling the spatial decay rate. During training, the model is supervised to match this transformed signal using voxelwise mean squared error (MSE):

\begin{equation}
\mathcal{L} = \frac{1}{L} \sum_{\ell=1}^L \frac{1}{|\mathcal{V}|} \sum_{v \in \mathcal{V}} \left( \hat{T}^\ell(v) - T^\ell(v) \right)^2
\end{equation}

\subsection{Imaging and Coordinate Data}

We make use of landmarks defined by the Anatomical Fiducials (AFIDs) protocol, a standardized set of 32 brain landmarks manually placed on structural T1-weighted MRI scans \cite{Lau2019-eh}. These fiducials span diverse anatomical regions, including subcortical nuclei, ventricular boundaries, and midline structures such as the anterior and posterior commissures. The imaging acquisition protocols, annotation procedures, and coordinate data used here are described in detail in Chapter~\ref{chap:afidsdata} but shown in Figure \ref{fig:ch3_Figure_data} for completeness.

For model development, all curated datasets were divided into training ($n = \textbf{148}$), validation ($n = \textbf{42}$), and testing ($n = \textbf{21}$) subsets. Stratified splitting of each dataset was used to ensure representative anatomical and demographic diversity across all sets.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_data.png}
    \caption{We make use of a previously released dataset containing anatomical fiducial (AFID) annotations. This dataset comprises eight sub-datasets spanning a range of MRI field strengths and neurodegenerative conditions. For machine learning modeling, we apply a stratified 70/20/10 split into training, validation, and test sets. By training on the combined heterogeneous dataset, the model is encouraged to learn features that are agnostic to imaging resolution, field strength, and MRI acquisition parameter differences.}
    \label{fig:ch3_Figure_data}
\end{figure}

\subsection{Preprocessing and Data Preparation}

We adopt standardized preprocessing profiles inspired by the nnU-Net framework \cite{Isensee2021-ev}, with additional modifications tailored for anatomical landmark detection. We build our workflow within a BIDS-compliant Snakemake \cite{Koster2012-ok} pipeline integrating with PyBIDS \cite{Yarkoni2019-lu} (i.e., SnakeBIDS; \url{https://github.com/khanlab/snakebids}). Input data were T1-weighted (T1w) structural MRIs, optionally converted from alternate contrasts (e.g., T2w, FLAIR, CT) using SynthSR \cite{Iglesias2023-co} when specified. 

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_proc.png}
    \caption{Overall preprocessing pipeline employed in \texttt{AutoAFIDs}. Preprocessing is generally modality specific but centered around processing T1w MRI. We make use of (1) SynthSR \cite{Iglesias2023-co} to convert various modalities (e.g., T2w, CT, or FLAIR) to T1w image. Subsequently, a T1w image goes through the following preprocessing steps: (2) bias correction \cite{Tustison2010-qu}, (3) rigid registration of an annotated template for landmak priors, (4) MRI volume intensity normalization performed using various user-specified options and finally (5) resampling of the MRI volume to an isotropic resolution. The SynthSR model already outputs images that do not need to undergo preprocessing steps 2 and 5.}
    \label{fig:ch3_Figure_proc}
\end{figure}


All T1w MRI scans undergo the following steps:

\begin{enumerate}
    \item \textbf{Bias field correction:} N4 bias field correction \cite{Tustison2010-nw} is applied to mitigate intensity non-uniformities arising from scanner-related artifacts.
    
    \item \textbf{Intensity normalization:} Image intensities are normalized on a per-volume basis using robust z-score normalization, enhancing contrast between tissue boundaries relevant for landmark detection. However, we also provide the option of min-max normalization.
    
    \item \textbf{Isotropic resampling:} All volumes are resampled to a uniform 1~mm isotropic resolution to ensure consistent spatial scaling across subjects.
    
    \item \textbf{Template-to-subject registration:} A rigid registration of the MNI152NLin2009cAsym template to each subject’s native space is performed using ANTs \cite{Avants2011-zs}. This transformation is applied only to restrict the inference search space and guide patch sampling, without altering anatomical label coordinates.
    
    \item \textbf{Patch extraction:} Volumes are divided into 3D patches centered around the expected landmark region. This local patching strategy reduces memory demands and encourages finer localization.
    
    \item \textbf{Spatial augmentations:} During training, 3D patches are augmented via random rigid rotations. Each rotation is applied about a uniformly sampled axis with an angle drawn from a normal distribution with zero mean and standard deviation $\sigma_{\text{angle}}$ (in degrees), promoting rotational robustness.
\end{enumerate}

Ground-truth heatmaps for each landmark are generated by computing the voxel-wise Euclidean distance (ED) to the target coordinate and applying an exponential decay function as described in Section \ref{sec:problemstatement}.

\subsection{Patch-Based Inference}

Rather than processing the entire volume, the model predicts landmarks using a patch-based strategy. For each target landmark $\ell$, we extract a cubic patch of size $2r+1$ centered on a prior coordinate $p_\ell^{\text{prior}}$ obtained by registering a standard template (e.g., MNI space) to the subject’s native image. Let $\mathcal{P}_\ell$ denote the local patch centered on $p_\ell^{\text{prior}}$:

\begin{equation}
\mathcal{P}_\ell = \left\{ v \in \mathcal{V} \ \middle|\ \lVert v - p_\ell^{\text{prior}} \rVert_\infty \leq r \right\}
\end{equation}

The input to the network is a single-channel image patch, and the output is a distance map over $\mathcal{P}_\ell$. The predicted landmark $\hat{p}_\ell$ is extracted as the centroid of the thresholded exponential-transformed output:

\begin{equation}
\hat{p}_\ell = \text{centroid} \left( \left\{ v \in \mathcal{P}_\ell \ \middle|\ \exp(-\alpha \cdot \hat{D}^\ell(v)) > \tau \right\} \right)
\end{equation}

where $\tau$ is a percentile-based threshold (e.g., top 1\%) applied to suppress noisy responses and extract a coherent region.

\subsection{Model Architecture and Training}

Each landmark is predicted using a separate deep neural network trained independently. The shared architecture is a lightweight 3D U-Net implemented in TensorFlow. Training was performed using the Adam optimizer with early stopping on a validation set. The loss function is mean squared error between the predicted and target distance maps (after exponential transform), as described above.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_cnn.png}
    \caption{Overview of the deep learning model architecture used for anatomical fiducial localization. The model is a 3D U-Net that takes as input a 3D patch centered around a prior landmark location. The network consists of convolutional blocks (Conv, 3×3×3), downsampling via max-pooling (2×2×2), and upsampling via transposed convolutions (UpConv, 2×2×2). Skip connections concatenate encoder and decoder feature maps to preserve spatial detail. The output is a single-channel distance map representing the ED from each voxel to the target anatomical landmark.}
    \label{fig:ch3_Figure_cnn}
\end{figure}


\subsection{Model Design Rationale}
In this work, we adopt a one-network-per-landmark training strategy. While many existing approaches predict all landmarks jointly using a multi-channel output architecture, we opt for training separate models for each anatomical point. This decision is motivated by two key considerations.

First, the anatomical heterogeneity of the landmarks poses a significant modeling challenge. The AFIDs span multiple tissue types and spatial contexts—including landmarks adjacent to ventricles, embedded within white matter tracts, and lying on cortical gray matter surfaces. These diverse appearance profiles often demand different spatial priors and texture sensitivities, which a shared model may struggle to learn simultaneously. Training distinct models allows each network to specialize in the local anatomical context of its assigned landmark, without interference from competing objectives. Second, certain use cases—such as deep brain stimulation (DBS)—require sub-voxel precision in landmark localization. Errors of just a few millimeters can lead to clinically significant deviations in surgical targeting or trajectory planning. In such high-stakes applications, even minor improvements in accuracy for individual landmarks can have meaningful downstream impact. By isolating each landmark into its own dedicated model, we maximize the opportunity for hyperparameter tuning, data augmentation, and architectural adaptation tailored to each target's anatomical and clinical importance. Together, these considerations justify a modular, per-landmark approach that prioritizes accuracy and adaptability over computational efficiency.

\section{Results}
\subsection{Landmark Localization Accuracy}
Model performance was evaluated on a held-out test set (n = 21) by computing the ED between predicted and ground truth AFID coordinates (see Table \ref{fig:ch3_Figure_autoscore}). Across all 32 anatomical landmarks (672 predictions in total), the model achieved high spatial accuracy, with a median ED of 1.21 mm and an interquartile range (IQR) of 0.76–1.95 mm. Per-landmark performance showed modest variability, reflecting differences in anatomical complexity, tissue contrast, and inter-subject variability. Ten landmarks exhibited median errors in the sub-millimetric range (0.4–0.9 mm), while more challenging regions, such as those adjacent to ventricular structures, demonstrated higher variability (2-2.4 mm). The maximum observed error across all landmarks was 5.28 mm. A complete summary of per-landmark accuracy is provided in Table~\ref{tab:autoafids_accuracy}.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_autoscore.png}
    \caption{Overview of localization error using \texttt{AutoAFIDs}. (a) Heatmap showing Euclidean distance errors (in mm) for each predicted anatomical landmark across 21 test subjects. Each column corresponds to one of the 32 AFIDs, and each row to a subject. (b) Spatial distribution of landmark-specific median prediction errors visualized on a glass brain. Each point represents the anatomical location of an AFID in stereotactic space, with marker size and color encoding the median error across subjects. Highter spatial variability in model accuracy was observed in lateral and ventricular landmarks.}
    \label{fig:ch3_Figure_autoscore}
\end{figure}

\subsection{Registration Evaluation Using \texttt{AutoAFIDs}}
To assess the utility of \texttt{AutoAFIDs} for evaluating registration quality, we compared its predicted landmark coordinates to those derived from \texttt{Lead-DBS} (v3.0; \cite{Neudorfer2023-wd}), a widely used software suite for DBS research that incorporates multi-stage nonlinear registration to align patient MRI data to MNI space. 

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.95\linewidth]{figs/ch3_Figure_cnnvslead2.png}
    \caption{Comparison between \texttt{AutoAFIDs} and \texttt{Lead-DBS} at landmark localization in native space. (a) Subject-wise median Euclidean distance (ED) errors across all landmarks. (b) Landmark-wise comparison of median ED for \texttt{AutoAFIDs} versus \texttt{Lead-DBS}. Points are colored by Wilcoxon signed-rank test significance. (c) Distribution of all EDs for \texttt{AutoAFIDs} (red) and \texttt{Lead-DBS} (blue), shown as overlapping histograms and cumulative frequency curves. Vertical dashed lines indicate medians.}
    \label{fig:ch3_Figure_cnnvslead}
\end{figure}

For both methods, subject-level median ED errors were computed across all 32 AFIDs, resulting in 21 paired measurements per method. The median ED across subjects was 1.21 mm for \texttt{AutoAFIDs} and 1.71 mm for \texttt{Lead-DBS}. A Wilcoxon signed-rank test revealed a statistically significant difference in localization error (p\(<\)0.001), indicating superior performance by \texttt{AutoAFIDs}. The distribution of subject-level and AFID-level errors is visualized in Figure~\ref{fig:ch3_Figure_cnnvslead}a and b, respectively. \texttt{AutoAFIDs} statistically outperformed \texttt{Lead-DBS} in 14 out of 32 AFIDs. Figure~\ref{fig:ch3_Figure_cnnvslead}c shows the full distribution of all landmark EDs and their cumulative frequencies.

Motivated by the variability observed in registration performance, we developed an automated QC application that uses \texttt{AutoAFIDs} to generate subject-specific summaries of registration accuracy. For each subject, our registration quality control tool computes descriptive statistics of ED across all 32 AFIDs. A qualitative review panel presents slice-wise visualizations for each AFID at cardinal planes with crosshairs centered on the registered and reference landmark coordinates. The report also includes a heatmap summarizing localization error by coordinate axis (x, y, z) and a 3D scatterplot visualizing landmark displacement between stereotactic space and the registered subject image. These features enable users to identify individual landmarks with high registration error, assess global alignment patterns, and quickly spot outliers. A sample report is provided in Figure~\ref{fig:figuresupregqc}.

\subsection{Brain Charting Using \texttt{AutoAFIDs}}

To explore how structural brain variability is encoded in pairwise AFID distances (Figure \ref{fig:ch3_Figure_pairwisedata}a), we analyzed a lifespan dataset of 2,834 subjects from nine publicly available neuroimaging cohorts (Figure \ref{fig:ch3_Figure_pairwisedata}b). Subjects ranged in age from 18 to 100 years, with an approximately even sex distribution (50.6\% female; Figure \ref{fig:ch3_Figure_pairwisedata}c) and broad diagnostic coverage (Figure \ref{fig:ch3_Figure_pairwisedata}d), including 2,000 cognitively normal (CN) individuals (70.6\%), 650 with Parkinson’s disease (PD, 22.9\%), and 184 with Alzheimer’s disease (AD, 6.5\%). AutoAFID annotations were successfully generated for all subjects, resulting in 496 pairwise distances per scan derived from 32 AFIDs. We apply a sex-stratified interquartile range (IQR; thresholded at 5 standard deviations) method to identify and remove outlier values for each distance feature, excluding extreme anatomical deviations likely to arise from poor AFID localization.

We first applied t-distributed stochastic neighbor embedding (t-SNE) to the standardized pairwise distance matrix to visualize population-level structure (Figure~\ref{fig:ch3_Figure_tsne}a-d). When colored by sex and age, the t-SNE embedding revealed a smooth gradient, suggesting that these demographic factors represent principal axes of anatomical variation within the AFID feature space. We observed modest separation by disease status, indicating potential disease-related morphometric signatures. In contrast, no clear clustering was observed by imaging site, suggesting that AFID-based morphometry is relatively robust to differences in image acquisition protocols.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_pairwisedata.png}
    \caption{(a) 3D plot showing all 496 pairwise connections between the 32 anatomical fiducials (AFIDs), illustrating the dense spatial sampling achieved across the brain. (b) Age distribution of subjects stratified by imaging site, demonstrating broad lifespan coverage and diverse dataset contributions. (c) Sex distribution by site, indicating approximate sex balance across most cohorts. (d) Distribution of subjects by disease status and sex, showing that the majority of participants are cognitively normal (CN), with additional representation from Parkinson’s disease (PD) and Alzheimer’s disease (AD) groups.
}
    \label{fig:ch3_Figure_pairwisedata}
\end{figure}

To examine how specific brain distances change across the lifespan, we computed Pearson correlations between each pairwise AFID distance and age among cognitively normal (CN) individuals. The top 10 positively and negatively correlated features are shown in Figure~\ref{fig:ch3_Figure_tsne}f,g. Several inter- and intra-regional distances demonstrated strong age dependence. The most positively correlated features primarily involved midline and posterior structures (e.g., AFID 13 to 12, 13 to 11), suggesting age-related expansion or elongation in these regions. Conversely, negatively correlated features predominantly involved anterior and subcortical structures (e.g., AFID 5 to 3, 3 to 2), indicating localized contraction or atrophy with age. These patterns reflect nonuniform aging trajectories across brain regions and highlight the sensitivity of coordinate-based morphometry to capture biologically meaningful structural changes.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_tsne.png}
    \caption{t-distributed stochastic neighbor embedding (t-SNE) embedding and age-related correlations in AFID distance space. (a–d) Two-dimensional t-SNE projection of subjects based on standardized AFID pairwise distances. Each point represents a subject and is colored by (a) sex, (b) age, (c) disease status, or (d) acquisition site. A clear gradient is observed along the age axis (b), while sex, disease, and site show limited separability, suggesting that age is the dominant source of variation in the AFID feature space. (f–g) Bar plots showing the top ten AFID pairwise distances with the strongest Pearson correlations with age. (f) Positively correlated distances primarily involve the mammillary bodies and temporal horn fiducials, reflecting expansion of periventricular and CSF spaces with age. (g) Negatively correlated distances involve brainstem and midbrain fiducials, potentially reflecting age-related compaction or atrophy along the brainstem axis.
    }
    \label{fig:ch3_Figure_tsne}
\end{figure}

Given its central role in stereotactic neurosurgery, we specifically examined age-related changes in the anterior commissure–posterior commissure (AC–PC) distance. Across cognitively normal individuals, we observed a small but consistent increase in AC–PC length with age in both sexes (Figure~\ref{fig:ch3_Figure_acpc}). Males had longer AC–PC distances than females (median ± IQR: 26.63 ± 1.48 mm vs. 25.81 ± 3.04 mm, respectively). In the PD subgroup, AC–PC distances were generally longer than in cognitively normal individuals. Males also had a longer AC-PC distance than females, median of 28.22 ± 5.14 mm vs. 27.25 ± 3.76 mm, respectively. To account for potential confounding by age, we performed age-matched comparisons of AC–PC distance between CN individuals and those with PD using a Mann-Whitney U test. Even after matching, AC–PC distances remained significantly longer in the PD group (p < 0.001), suggesting disease-associated structural changes along this canonical axis. This reinforces the relevance of individualized targeting in stereotactic applications where the AC–PC line serves as a key anatomical reference.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1\linewidth]{figs/ch3_Figure_acpc.png}
    \caption{
    Analysis of the anterior commissure–posterior commissure (AC–PC) line across age and disease. (a) Anatomical definition of the AC (left) and PC (right) landmarks shown in axial, sagittal, and coronal views. (b) Age-related trends in AC–PC distance among cognitively normal cohort. A subtle increase in distance is observed with age, with males showing longer distances than females. (c) AC–PC distances in individuals with Parkinson’s disease. A similar age-related trend is observed. Shaded bands represent 95\% confidence intervals for sex-stratified second-order polynomial fits.
    }
    \label{fig:ch3_Figure_acpc}
\end{figure}

\section{Discussion}
In this study, we introduce \texttt{AutoAFIDs}, an open-source deep learning-based framework for automatic localization of anatomical fiducials (AFIDs) with millimetric accuracy. Our data and code is designed for generalizability, enabling incorporation into various software compatible with the BIDS specification. \texttt{AutoAFIDs} can quality control registration and capture morphometric changes in the human brain. This work introduces a novel framework for stereotactic brain charting across the human lifespan, which we leverage to characterize morphometric changes in neurodegenerative disease.

\subsection{Landmark Localization Performance}

\texttt{AutoAFIDs} achieved a median Euclidean distance (ED) of 1.21 mm (IQR: 0.76–1.95 mm) across 32 AFIDs in a held-out test set of 21 subjects. These results are in line with the range reported for similar tasks \cite{Ertl2025-wu, Salari2024-iu, Edwards2021-su} and approach expert-level precision (0-2 mm), particularly for brainstem landmarks \cite{Abbass2022-lf}. Ten of the 32 AFIDs showed sub-millimetric median errors, while more anatomically variable or low-contrast regions, such as those near the ventricles, exhibited higher variability. This was also consistent with prior reports of inter-rater localization accuracy \cite{Lau2019-eh, Abbass2022-lf}. Although we did not perform a direct comparison between \texttt{AutoAFIDs} and inter-rater localization accuracy, we direct the reader to Chapter \ref{chap:afidsdata} where we provide a breakdown of inter-rater localization accuracy across all AFID datasets. 

Several competing models for landmark localization in brain MRI offer direct points of comparison as they make use of the AFIDs data we released in Chapter~\ref{chap:afidsdata}. Among them, \texttt{nnLandmark} \cite{Ertl2025-wu} reported an average localization error of approximately 1.27 mm. However, per-landmark accuracy was not reported, limiting insight into how the model performs across anatomically diverse regions, particularly in challenging areas such as those near the ventricular system. Given that \texttt{nnLandmark} also employs a U-Net architecture, the overall similarity in accuracy is expected. A notable limitation of \texttt{nnLandmark} is the lack of a released codebase and its absence of compatibility with the BIDS specification. This increases the technical burden for neuroimaging researchers and developers, who must independently integrate model inference into large-scale, BIDS-compliant workflows. \texttt{DeepNavNet} \cite{Edwards2021-su}, which uses a 3D residual network architecture, focuses on localizing the anterior and posterior commissures for neuronavigation. \cite{Edwards2021-su} reported localization errors of 0.79 ± 0.33 mm and 0.78 ± 0.33 mm for the AC and PC respectively. These results are comparable to \texttt{AutoAFIDs}’ performance for those same landmarks (AC: 0.42 mm, PC: 0.83 mm), demonstrating \texttt{AutoAFIDs}' competitive accuracy even relative to models specialized for only two targets. In contrast, \cite{Salari2024-iu} developed \texttt{CABLD}, which is a contrast-agnostic self-supervised approach to landmark regression that involves the annotation of a single reference example. While this flexibility is notable, \texttt{CABLD}'s reported accuracy is on the order of 3-4 mm. This level of performance is insufficient for millimetric applications such as registration quality control, where we show that even established nonlinear pipelines like \texttt{Lead-DBS} achieve median landmark alignment errors around 1.7 mm. \texttt{CABLD}’s lower accuracy, therefore, restricts its utility in precision-demanding use cases.

A key strength of \texttt{AutoAFIDs} lies in its design where each landmark is treated as a separate supervised learning task with its own dedicated model. This modular, per-landmark approach means that new anatomical targets can be easily added to the framework without retraining the entire system. It also enables more tailored optimization for each landmark, which may be especially important for landmarks with distinct spatial or contrast features. Another strength of \texttt{AutoAFIDs} is the modular and user-facing configuration (See Supplementary content \ref{app:yaml}) which is compatible with the BIDS specification. To our knowledge, no current BIDS-aware tools exist in the literature. This flexibility, combined with consistent sub-millimetric to low-millimetric accuracy, positions \texttt{AutoAFIDs} as a scalable tool for high-resolution brain mapping and surgical planning.

\subsection{Evaluation of Registration Accuracy}

We benchmarked \texttt{AutoAFIDs} against \texttt{Lead-DBS}, a widely adopted pipeline for nonlinear registration in DBS research. \texttt{AutoAFIDs} significantly outperformed \texttt{Lead-DBS} on landmark localization accuracy across subjects and AFIDs (p\(<\)0.001), with superior performance in 14 of 32 landmarks. This suggests that direct landmark prediction may complement or even surpass deformation-based alignment in capturing subject-specific anatomical variability. It is also important to note that \texttt{Lead-DBS} employs a rigorously validated registration scheme and was curated by comparisons of six modern and established algorithms \cite{Ewert2019-cc}. Thus, \texttt{Lead-DBS} serves as a strong benchmark for comparison, though it may overestimate the performance of general-purpose in-house registration tools. Beyond group-level accuracy, \texttt{AutoAFIDs} also provides a valuable framework for registration quality control by generating intuitive, subject-specific visualizations and quantitative error summaries. To our knowledge, no existing open-source tools offer automatic and reproducible metrics for evaluating registration accuracy; most neuroimaging software still relies on qualitative visual inspection. By enabling the detection and quantification of misalignments, \texttt{AutoAFIDs} promotes greater transparency and accountability in image preprocessing—an increasingly important consideration as neuroimaging and neurosurgical workflows become more reliant on automated pipelines.

\subsection{Structural Brain Charting Across the Lifespan}
We demonstrated that pairwise distances between AFIDs, automatically predicted using \texttt{AutoAFIDs}, capture meaningful structural variation across the human lifespan and provide a robust framework for population-level morphometric analysis. By analyzing 2,834 MRIs from nine diverse public neuroimaging cohorts, we show that coordinate-based representations of brain anatomy can encode individual differences related to age, sex, and disease status, while remaining resilient to variability in imaging site and acquisition protocol.

Dimensionality reduction via t-SNE revealed that age and sex are principal axes of variation in the AFID-derived feature space, consistent with prior studies that report global and regional brain volume changes associated with these demographic factors \cite{Fjell2010-aq, Ritchie2018-df}. The continuous age gradient observed in the embedding indicates that AFID pairwise distances encode smooth anatomical changes across the lifespan, likely reflecting progressive atrophy, ventricular expansion, and sulcal widening. Notably, the minimal clustering by acquisition site supports the modality-agnostic potential of this framework, underscoring its utility for multi-cohort studies where scanner variability often confounds traditional voxelwise analyses \cite{Fortin2018-ke}.

Our correlation analysis of cognitively normal individuals identified both positive and negative associations between specific AFID distances and age. Positively correlated features primarily involved periventricular, such as frontal and temporal horn fiducials, aligning with known age-related ventricular enlargement and posterior brain expansion \cite{Resnick2003-je}. Conversely, negatively correlated distances spanned anterior and subcortical regions, such as the brainstem and midbrain, supporting prior reports of early-onset atrophy in these areas \cite{Raz2005-jr}. These findings highlight the ability of AFID-based morphometry to resolve localized, directional patterns of anatomical change that may be masked in global metrics.

The lack of strong disease-specific clustering in the t-SNE embedding suggests that while coordinate-based features are sensitive to broad morphometric changes, finer-grained modeling may be necessary to uncover subtle disease-related patterns. However, the modest separation of Parkinson’s disease (PD) and Alzheimer’s disease (AD) subjects from cognitively normal individuals in some regions of the embedding hints at latent structure that could be further disentangled using supervised classification or longitudinal modeling. Importantly, the minimal influence of acquisition site variability confirms that the AFID-based feature space may generalize well to clinical datasets collected across institutions, an essential property for developing robust disease biomarkers.

While these results are promising, several limitations pretaining to this analysis must be acknowledged. First, AFID pairwise distances provide a compact but reduced representation of brain anatomy that omits cortical surface geometry and tissue contrast features, which may limit sensitivity to some morphometric patterns. Second, our analysis focused on cross-sectional data; future work incorporating longitudinal scans will be essential to directly model trajectories of anatomical change. Third, while we removed extreme outlier values using a sex-stratified IQR approach, more sophisticated quality control procedures (e.g., leveraging spatial priors or uncertainty estimation) could further improve feature robustness. Finally, although we explored only linear correlations with age, non-linear relationships—especially in developmental or late-life stages—may be better captured with advanced statistical or machine learning models.

\subsection{Clinical Relevance of the AC–PC Line}
Given its central role in neurosurgical targeting, we analyzed the anterior commissure–posterior commissure (AC–PC) distance—a canonical stereotactic reference axis. In cognitively normal individuals, we observed a subtle but consistent increase in AC–PC length with age, as well as longer distances in males compared to females. These findings align with prior reports that link AC–PC length to demographic variation, including age- and sex-associated neuroanatomical changes \cite{Lee2008-nd}. Our analysis also revealed that patients with PD exhibited significantly greater AC–PC distances than age-matched controls. This observation is consistent with a prior studies by \cite{Lee2008-nd,Dabadi2020-am}. Importantly, traditional stereotactic systems often rely on standardized templates or fixed AC–PC-based reference coordinates. Our findings reinforce the necessity of individualized anatomical localization to ensure accurate deep brain stimulation (DBS) targeting. By enabling automated and precise identification of stereotactic landmarks, \texttt{AutoAFIDs} provides a scalable solution to incorporate subject-specific geometry into surgical planning.

\subsection{Limitations and Future Directions}

While \texttt{AutoAFIDs} exhibits strong performance and broad applicability, several limitations should be acknowledged to contextualize the results and guide future improvements:

The model was trained and evaluated on manually placed AFIDs. While these annotations were performed by expert raters following a standardized protocol, inter-rater variability remains a source of noise in the ground truth labels, particularly in regions with ambiguous anatomical boundaries or low image contrast. Previous work has demonstrated that millimetric variation can arise even among trained experts when localizing ventricular landmarks \cite{Lau2019-eh,Abbass2022-lf}, which may ultimately limit the ceiling performance of supervised models trained on such data. Incorporating probabilistic labels or multi-rater consensus strategies could mitigate these effects in future iterations.

Our use of a 3D U-Net architecture enabled accurate, anatomically aware localization, but it may not be optimal for all types of landmarks. Alternative architectures—such as attention-based networks or models inspired by YOLO \cite{Redmon2015-ia}—have demonstrated state-of-the-art performance in object detection tasks. However, these models typically require more complex training regimes, greater computational resources, and are not as widely adopted in 3D medical imaging pipelines. Our decision to use a U-Net was motivated by its established performance in 3D medical image segmentation \cite{Cicek2016-dz}, ease of integration with 3D patch-based training, and its competitive accuracy compared to inter-rater variability. Future work may explore hybrid or attention-enhanced architectures to improve landmark resolution, particularly in morphologically heterogeneous regions.

To enhance generalizability beyond T1-weighted inputs, we employed SynthSR \cite{Iglesias2023-co}, a widely used domain-adaptive tool that synthesizes 1~mm isotropic MP2RAGE-like volumes from various input modalities (e.g., T2w, FLAIR, CT). While this enables broader applicability of \texttt{AutoAFIDs} in various contexts where high-resolution T1w images may be unavailable, SynthSR has not been explicitly validated for millimetric accuracy in stereotactic applications. As such, we include warnings in the software documentation advising caution when applying the model to non-T1w modalities and encourage users to visually inspect results. Rigorous validation of SynthSR-based inference remains an important future direction, particularly as synthetic image pipelines gain traction in neurosurgical planning.

Finally, although we presented initial analyses of brain morphometry and disease-related variability using \texttt{AutoAFIDs}, these were intended as proof-of-concept demonstrations. The curated dataset enables a much deeper exploration of anatomical differences across lifespan and disease states, including longitudinal and progression-related changes. We view this paper as the first step in that direction, and future studies will leverage \texttt{AutoAFIDs} to more systematically investigate these questions.

In summary, \texttt{AutoAFIDs} provides a strong foundation for accurate and interpretable landmark localization, but future work will benefit from exploring architectural advances, modality-specific refinements, and large-scale morphometric modeling to realize its full potential.

\section{Conclusion}

\texttt{AutoAFIDs} offers a generalizable, high-accuracy tool for automatic anatomical landmark localization. Its ability to detect subtle structural variation, assess registration quality, and enable coordinate-based brain morphometry opens new possibilities for scalable, interpretable, and individualized neuroimaging analysis. As interest in reproducible and large-scale neuroimaging grows, \texttt{AutoAFIDs} can serve as a tool toward quality control and advancing precision brain mapping.



